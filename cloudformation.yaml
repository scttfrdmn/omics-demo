AWSTemplateFormatVersion: '2010-09-09'
Description: 'CloudFormation template for 15-minute Omics Demo'

Parameters:
  DataBucketName:
    Type: String
    Description: Name of the S3 bucket to store input and output data
    Default: omics-demo-bucket

  KeyPairName:
    Type: String
    Description: EC2 Key Pair for SSH access
    Default: omics-demo-key

Resources:
  # VPC and Networking resources
  OmicsVPC:
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock: 10.0.0.0/16
      EnableDnsSupport: true
      EnableDnsHostnames: true
      Tags:
        - Key: Name
          Value: OmicsVPC

  PublicSubnet1:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref OmicsVPC
      CidrBlock: 10.0.1.0/24
      AvailabilityZone: !Select [ 0, !GetAZs '' ]
      MapPublicIpOnLaunch: true
      Tags:
        - Key: Name
          Value: OmicsPublicSubnet1

  PublicSubnet2:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref OmicsVPC
      CidrBlock: 10.0.2.0/24
      AvailabilityZone: !Select [ 1, !GetAZs '' ]
      MapPublicIpOnLaunch: true
      Tags:
        - Key: Name
          Value: OmicsPublicSubnet2

  PrivateSubnet1:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref OmicsVPC
      CidrBlock: 10.0.3.0/24
      AvailabilityZone: !Select [ 0, !GetAZs '' ]
      Tags:
        - Key: Name
          Value: OmicsPrivateSubnet1

  PrivateSubnet2:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref OmicsVPC
      CidrBlock: 10.0.4.0/24
      AvailabilityZone: !Select [ 1, !GetAZs '' ]
      Tags:
        - Key: Name
          Value: OmicsPrivateSubnet2

  InternetGateway:
    Type: AWS::EC2::InternetGateway
    Properties:
      Tags:
        - Key: Name
          Value: OmicsIGW

  GatewayAttachment:
    Type: AWS::EC2::VPCGatewayAttachment
    Properties:
      VpcId: !Ref OmicsVPC
      InternetGatewayId: !Ref InternetGateway

  PublicRouteTable:
    Type: AWS::EC2::RouteTable
    Properties:
      VpcId: !Ref OmicsVPC
      Tags:
        - Key: Name
          Value: OmicsPublicRouteTable

  PublicRoute:
    Type: AWS::EC2::Route
    DependsOn: GatewayAttachment
    Properties:
      RouteTableId: !Ref PublicRouteTable
      DestinationCidrBlock: 0.0.0.0/0
      GatewayId: !Ref InternetGateway

  PublicSubnet1RouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref PublicSubnet1
      RouteTableId: !Ref PublicRouteTable

  PublicSubnet2RouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref PublicSubnet2
      RouteTableId: !Ref PublicRouteTable

  # Security Groups
  BatchSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Security group for AWS Batch compute resources
      VpcId: !Ref OmicsVPC
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 22
          ToPort: 22
          CidrIp: 0.0.0.0/0
      Tags:
        - Key: Name
          Value: BatchSecurityGroup

  # IAM Roles
  BatchServiceRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: batch.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSBatchServiceRole

  BatchInstanceRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: ec2.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy
        - arn:aws:iam::aws:policy/AmazonS3FullAccess

  BatchInstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      Roles:
        - !Ref BatchInstanceRole

  LambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
        - arn:aws:iam::aws:policy/AmazonS3FullAccess
        - arn:aws:iam::aws:policy/AmazonBatchFullAccess

  # S3 Bucket
  DataBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Ref DataBucketName
      VersioningConfiguration:
        Status: Enabled
      LifecycleConfiguration:
        Rules:
          - Id: DeleteOldResults
            Status: Enabled
            ExpirationInDays: 30
            Prefix: results/

  # AWS Batch Resources - Graviton CPU Environment
  GravitonComputeEnvironment:
    Type: AWS::Batch::ComputeEnvironment
    Properties:
      Type: MANAGED
      ServiceRole: !GetAtt BatchServiceRole.Arn
      ComputeResources:
        Type: SPOT
        MaxvCpus: 256
        MinvCpus: 0
        DesiredvCpus: 0
        InstanceTypes:
          - c7g.large
          - c7g.xlarge
          - c7g.2xlarge
          - c7g.4xlarge
          - c7g.8xlarge
        Subnets:
          - !Ref PrivateSubnet1
          - !Ref PrivateSubnet2
        SecurityGroupIds:
          - !Ref BatchSecurityGroup
        InstanceRole: !Ref BatchInstanceProfile
        SpotIamFleetRole: !GetAtt SpotFleetRole.Arn
        BidPercentage: 60
        AllocationStrategy: SPOT_CAPACITY_OPTIMIZED
      State: ENABLED

  # AWS Batch Resources - GPU Environment
  GpuComputeEnvironment:
    Type: AWS::Batch::ComputeEnvironment
    Properties:
      Type: MANAGED
      ServiceRole: !GetAtt BatchServiceRole.Arn
      ComputeResources:
        Type: SPOT
        MaxvCpus: 64
        MinvCpus: 0
        DesiredvCpus: 0
        InstanceTypes:
          - g5g.xlarge
          - g5g.2xlarge
          - g5g.4xlarge
        Subnets:
          - !Ref PrivateSubnet1
          - !Ref PrivateSubnet2
        SecurityGroupIds:
          - !Ref BatchSecurityGroup
        InstanceRole: !Ref BatchInstanceProfile
        SpotIamFleetRole: !GetAtt SpotFleetRole.Arn
        BidPercentage: 60
        AllocationStrategy: SPOT_CAPACITY_OPTIMIZED
      State: ENABLED

  # Spot Fleet IAM Role
  SpotFleetRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: spotfleet.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AmazonEC2SpotFleetTaggingRole

  # AWS Batch Job Queues
  CPUJobQueue:
    Type: AWS::Batch::JobQueue
    Properties:
      Priority: 1
      State: ENABLED
      ComputeEnvironmentOrder:
        - Order: 1
          ComputeEnvironment: !Ref GravitonComputeEnvironment

  GPUJobQueue:
    Type: AWS::Batch::JobQueue
    Properties:
      Priority: 1
      State: ENABLED
      ComputeEnvironmentOrder:
        - Order: 1
          ComputeEnvironment: !Ref GpuComputeEnvironment

  # AWS Batch Job Definitions
  NextflowJobDefinition:
    Type: AWS::Batch::JobDefinition
    Properties:
      Type: container
      ContainerProperties:
        Image: public.ecr.aws/nextflow/nextflow:latest
        ResourceRequirements:
          - Type: VCPU
            Value: "2"
          - Type: MEMORY
            Value: "4096"
        Command:
          - nextflow
          - run
          - main.nf
          - -profile
          - aws
        Volumes:
          - Host:
              SourcePath: /tmp
            Name: tmp
        MountPoints:
          - ContainerPath: /tmp
            ReadOnly: false
            SourceVolume: tmp
      RetryStrategy:
        Attempts: 3
      Timeout:
        AttemptDurationSeconds: 900

  AdmixtureGpuJobDefinition:
    Type: AWS::Batch::JobDefinition
    Properties:
      Type: container
      ContainerProperties:
        Image: public.ecr.aws/lts/admixture:latest
        ResourceRequirements:
          - Type: VCPU
            Value: "4"
          - Type: MEMORY
            Value: "16384"
          - Type: GPU
            Value: "1"
        Command:
          - --vcf
          - s3://bucket/file.vcf
          - --output
          - s3://bucket/output
        Volumes:
          - Host:
              SourcePath: /tmp
            Name: tmp
        MountPoints:
          - ContainerPath: /tmp
            ReadOnly: false
            SourceVolume: tmp
      RetryStrategy:
        Attempts: 3
      Timeout:
        AttemptDurationSeconds: 900

  # Cost Dashboard
  CostDashboard:
    Type: AWS::CloudWatch::Dashboard
    Properties:
      DashboardName: !Sub "${AWS::StackName}-cost-dashboard"
      DashboardBody: !Sub |
        {
          "widgets": [
            {
              "type": "metric",
              "x": 0,
              "y": 0,
              "width": 24,
              "height": 6,
              "properties": {
                "metrics": [
                  [ "AWS/Billing", "EstimatedCharges", "ServiceName", "AmazonEC2", "Currency", "USD" ],
                  [ ".", ".", ".", "AmazonS3", ".", "." ],
                  [ ".", ".", ".", "AWSBatch", ".", "." ],
                  [ ".", ".", ".", "AWSLambda", ".", "." ]
                ],
                "view": "timeSeries",
                "stacked": false,
                "region": "${AWS::Region}",
                "title": "Estimated Charges by Service",
                "period": 60,
                "stat": "Maximum"
              }
            },
            {
              "type": "metric",
              "x": 0,
              "y": 6,
              "width": 12,
              "height": 6,
              "properties": {
                "metrics": [
                  [ "AWS/Batch", "CPUUtilization", "JobQueue", "${CPUJobQueue}" ],
                  [ ".", "MemoryUtilization", ".", "." ]
                ],
                "view": "timeSeries",
                "stacked": false,
                "region": "${AWS::Region}",
                "title": "CPU Job Queue Resource Utilization",
                "period": 60,
                "stat": "Average"
              }
            },
            {
              "type": "metric",
              "x": 12,
              "y": 6,
              "width": 12,
              "height": 6,
              "properties": {
                "metrics": [
                  [ "AWS/Batch", "CPUUtilization", "JobQueue", "${GPUJobQueue}" ],
                  [ ".", "MemoryUtilization", ".", "." ],
                  [ ".", "GPUUtilization", ".", "." ]
                ],
                "view": "timeSeries",
                "stacked": false,
                "region": "${AWS::Region}",
                "title": "GPU Job Queue Resource Utilization",
                "period": 60,
                "stat": "Average"
              }
            }
          ]
        }

  # Lambda for orchestration
  OrchestratorLambda:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.handler
      Role: !GetAtt LambdaExecutionRole.Arn
      Runtime: python3.9
      Timeout: 300
      MemorySize: 128
      Code:
        ZipFile: |
          import boto3
          import os
          import json
          import time
          
          def handler(event, context):
              """
              Orchestrates the omics demo workflow by submitting batch jobs
              and monitoring their progress.
              """
              # Initialize clients
              batch = boto3.client('batch')
              s3 = boto3.client('s3')
              
              # Get environment variables
              job_queue = os.environ['JOB_QUEUE']
              job_definition = os.environ['JOB_DEFINITION']
              data_bucket = os.environ['DATA_BUCKET']
              
              # Submit the main job
              response = batch.submit_job(
                  jobName='omics-demo-{}'.format(int(time.time())),
                  jobQueue=job_queue,
                  jobDefinition=job_definition,
                  containerOverrides={
                      'command': [
                          'nextflow',
                          'run',
                          'main.nf',
                          '-profile',
                          'aws',
                          '--samples',
                          's3://{}/input/sample_list.csv'.format(data_bucket),
                          '--output',
                          's3://{}/results'.format(data_bucket)
                      ]
                  }
              )
              
              job_id = response['jobId']
              print(f"Submitted job with ID: {job_id}")
              
              return {
                  'statusCode': 200,
                  'body': json.dumps({
                      'message': 'Successfully submitted job',
                      'jobId': job_id
                  })
              }

      Environment:
        Variables:
          JOB_QUEUE: !Ref CPUJobQueue
          JOB_DEFINITION: !Ref NextflowJobDefinition
          DATA_BUCKET: !Ref DataBucketName

Outputs:
  DataBucketName:
    Description: Name of the S3 bucket for data storage
    Value: !Ref DataBucket

  CPUJobQueueArn:
    Description: ARN of the CPU Job Queue
    Value: !Ref CPUJobQueue

  GPUJobQueueArn:
    Description: ARN of the GPU Job Queue
    Value: !Ref GPUJobQueue

  CostDashboardURL:
    Description: URL of the Cost Dashboard
    Value: !Sub "https://${AWS::Region}.console.aws.amazon.com/cloudwatch/home?region=${AWS::Region}#dashboards:name=${CostDashboard}"

  OrchestratorLambdaArn:
    Description: ARN of the Orchestrator Lambda
    Value: !GetAtt OrchestratorLambda.Arn
